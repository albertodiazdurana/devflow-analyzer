{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DevFlow Analyzer Demo\n",
    "\n",
    "This notebook demonstrates the core capabilities of DevFlow Analyzer:\n",
    "1. Process mining analysis of CI/CD data\n",
    "2. DFG visualization\n",
    "3. Agent-based investigation\n",
    "4. Report generation\n",
    "5. Experiment tracking with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "import sys\n",
    "sys.path.insert(0, '..')  # Add parent directory to path\n",
    "\n",
    "from pathlib import Path\n",
    "from src.process_analyzer import ProcessAnalyzer\n",
    "from src.agent import DevFlowAgent\n",
    "from src.llm_reporter import LLMReporter\n",
    "from src.llm_provider import get_available_models\n",
    "from src.evaluation import ExperimentTracker, Timer, compute_cost\n",
    "\n",
    "print(\"Available models:\", get_available_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load and Analyze CI/CD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Process Analysis\n",
    "analyzer = ProcessAnalyzer()\n",
    "analyzer.load_data(Path('../data/sample/travistorrent_10k.csv'))\n",
    "\n",
    "result = analyzer.analyze()\n",
    "\n",
    "print(f\"Builds analyzed: {result.n_builds:,}\")\n",
    "print(f\"Projects: {result.n_projects}\")\n",
    "print(f\"Date range: {result.date_range_start} to {result.date_range_end}\")\n",
    "print(f\"\\nSuccess rate: {result.overall_success_rate:.1%}\")\n",
    "print(f\"Failure rate: {result.overall_failure_rate:.1%}\")\n",
    "print(f\"Error rate: {result.overall_error_rate:.1%}\")\n",
    "print(f\"\\nMedian duration: {result.median_duration_seconds:.0f}s\")\n",
    "print(f\"P90 duration: {result.p90_duration_seconds:.0f}s\")\n",
    "print(f\"\\nBottlenecks detected: {len(result.bottlenecks) if result.bottlenecks else 0}\")\n",
    "print(f\"Projects at risk: {len(result.projects_at_risk) if result.projects_at_risk else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Generate DFG Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: DFG Visualization\n",
    "from IPython.display import Image, display\n",
    "\n",
    "dfg_path = Path('../outputs/figures/dfg_demo.png')\n",
    "dfg_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "analyzer.generate_dfg(dfg_path)\n",
    "print(f\"DFG saved to: {dfg_path}\")\n",
    "\n",
    "# Display the image\n",
    "display(Image(filename=str(dfg_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Agent Investigation\n",
    "\n",
    "The DevFlow Agent uses ReAct pattern with tools to autonomously investigate CI/CD issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Agent Investigation\n",
    "agent = DevFlowAgent(model_key='gpt-4o-mini', temperature=0.3)\n",
    "\n",
    "question = \"Which projects have the highest failure rates and what might be causing the issues?\"\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"Agent investigating...\\n\")\n",
    "\n",
    "with Timer() as timer:\n",
    "    response = agent.investigate(result, question)\n",
    "\n",
    "print(response)\n",
    "print(f\"\\n---\\nLatency: {timer.elapsed_ms:.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Full Report Generation\n",
    "\n",
    "Generate a structured report with all sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Full Report\n",
    "from IPython.display import Markdown\n",
    "\n",
    "reporter = LLMReporter(model_key='gpt-4o-mini', temperature=0.7)\n",
    "\n",
    "print(\"Generating full report...\\n\")\n",
    "\n",
    "with Timer() as timer:\n",
    "    report = reporter.generate_report(result)\n",
    "\n",
    "print(f\"Report generated in {timer.elapsed_ms:.0f}ms\\n\")\n",
    "\n",
    "# Display as formatted markdown\n",
    "display(Markdown(report.to_markdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Experiment Tracking with MLflow\n",
    "\n",
    "Track experiments for reproducibility and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Experiment Tracking\n",
    "tracker = ExperimentTracker('demo-notebook')\n",
    "\n",
    "with tracker.start_run('demo-analysis', tags={'notebook': 'demo'}):\n",
    "    # Log parameters\n",
    "    tracker.log_params({\n",
    "        'model_key': 'gpt-4o-mini',\n",
    "        'n_builds': result.n_builds,\n",
    "        'n_projects': result.n_projects,\n",
    "    })\n",
    "    \n",
    "    # Run agent analysis\n",
    "    agent = DevFlowAgent(model_key='gpt-4o-mini')\n",
    "    \n",
    "    with Timer() as timer:\n",
    "        response = agent.investigate(result, 'Summarize the CI/CD health in 3 bullet points.')\n",
    "    \n",
    "    # Estimate tokens and cost\n",
    "    input_tokens = len(result.to_llm_context()) // 4\n",
    "    output_tokens = len(response) // 4\n",
    "    cost = compute_cost('gpt-4o-mini', input_tokens, output_tokens)\n",
    "    \n",
    "    # Log metrics\n",
    "    tracker.log_metrics({\n",
    "        'latency_ms': timer.elapsed_ms,\n",
    "        'input_tokens': input_tokens,\n",
    "        'output_tokens': output_tokens,\n",
    "        'cost_usd': cost,\n",
    "    })\n",
    "    \n",
    "    # Log artifact\n",
    "    tracker.log_artifact(response, 'agent_response.md')\n",
    "\n",
    "print(\"Experiment logged to MLflow!\")\n",
    "print(f\"\\nAgent response:\\n{response}\")\n",
    "print(f\"\\nMetrics: {timer.elapsed_ms:.0f}ms, ${cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demo showed:\n",
    "1. **Process Mining**: Loading and analyzing CI/CD build data with PM4Py\n",
    "2. **Visualization**: Generating Directly-Follows Graphs\n",
    "3. **Agent Analysis**: ReAct-style agent investigating issues autonomously\n",
    "4. **Report Generation**: Structured LLM-powered reports\n",
    "5. **Experiment Tracking**: MLflow integration for reproducibility\n",
    "\n",
    "To run the full Streamlit application:\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "To view MLflow experiments:\n",
    "```bash\n",
    "mlflow ui --port 5000\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
